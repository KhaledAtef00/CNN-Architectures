{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport tqdm\nimport torch\nimport torchvision\nimport torchvision.transforms as transforms\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if(torch.cuda.is_available()):\n    device = torch.device('cuda')\nelif(torch.backends.mps.is_available()):\n    device = torch.device('mps')\nelse:\n    device = torch.device('cpu')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"IMAGE_SIZE = 32\nbatch_size = 32\nmean, std = torch.tensor([0.4914, 0.4822, 0.4465]), torch.tensor([0.247, 0.243, 0.261])\n# These values are mostly used by researchers as found to very useful in fast convergence\n\n\ntransform = transforms.Compose([\n    transforms.RandomRotation(0.2) ,\n    transforms.RandomHorizontalFlip() ,\n    transforms.RandomVerticalFlip() ,\n    transforms.ColorJitter(),\n    transforms.ToTensor(),\n    transforms.Normalize(mean, std)\n])\n\n\n\ntrain_dataset = torchvision.datasets.CIFAR10(root='./data', train=True,download=True, transform=transform)\nval_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n\ntrain_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size , shuffle = True)\n\nval_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size , shuffle = False)\n\nclasses = [ 'airplane', 'automobile', 'bird', 'cat','deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n\n\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def imshow(img):\n    img = img / 2 + 0.5     # unnormalize\n    npimg = img.numpy()\n    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n    plt.show()\n\n\n# get some random training images\ndataiter = iter(train_loader)\nimages, labels = next(dataiter)\n\n# show images\nimshow(torchvision.utils.make_grid(images))\n# print labels\nprint(' '.join(f'{classes[labels[j]]:5s}' for j in range(batch_size)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(train_dataset.data.shape  , \" - \" , val_dataset.data.shape)\nprint(len(train_dataset.targets))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# functions to show an image\n\ndef unnormalize(img):\n        # unnormalize\n    img[0]= img[0]*std[0] + mean[0]\n    img[1]= img[1]*std[1] + mean[1]\n    img[2]= img[2]*std[2] + mean[2]\n    return img\n    \ndef imshow(img):\n    # unnormalize\n    img = unnormalize(img)\n    npimg = img.numpy()\n    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n    plt.show()\n    \ndef im_convert(tensor):\n    img = tensor.cpu().clone().detach().numpy() #\n    img = img.transpose(1, 2, 0)\n    img = img * np.array(tuple(mean)) + np.array(tuple(std))\n    img = img.clip(0, 1) # Clipping the size to print the images later\n    return img\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure(figsize=(20, 10)) \n\nfor i in range(len(classes)):\n    dataiter = iter(train_loader)\n    images, labels = next(dataiter)\n    for j in range (len(labels)):\n        if(labels[j].item() == i):\n            ax = fig.add_subplot(2, 5, i+1, xticks=[], yticks=[])\n            plt.imshow(im_convert(images[j]))\n            ax.set_title(classes[i])\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(len(classes)):\n    dataiter = iter(train_loader)\n    images, labels = next(dataiter)\n    for j in range (len(labels)):\n        if(labels[j].item() == i):\n            print(classes[i])\n            imshow(images[j])\n            break","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class conv_block(nn.Module):\n    def __init__(self, in_channels, out_channels, kernel_size, **kwargs):\n        super(conv_block, self).__init__()\n        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, **kwargs)\n        self.relu = nn.ReLU(inplace=True)\n    \n    def forward(self, x):\n        x = self.conv(x)\n        x = self.relu(x)\n        return x\n#red --> reduction \nclass Inception_block(nn.Module):\n    def __init__(self, in_channels, ch1x1, ch3x3red, ch3x3, ch5x5red, ch5x5, pool_proj):\n        super(Inception_block, self).__init__()\n        # 1x1 convolution branch\n        self.branch1 = conv_block(in_channels, ch1x1, kernel_size=1, stride=1, padding=0)\n        \n        # 1x1 convolution followed by 3x3 convolution branch\n        self.branch2 = nn.Sequential(\n            conv_block(in_channels, ch3x3red, kernel_size=1, stride=1, padding=0),\n            conv_block(ch3x3red, ch3x3, kernel_size=3, stride=1, padding=1)\n        )\n        \n        # 1x1 convolution followed by 5x5 convolution branch\n        self.branch3 = nn.Sequential(\n            conv_block(in_channels, ch5x5red, kernel_size=1, stride=1, padding=0),\n            conv_block(ch5x5red, ch5x5, kernel_size=5, stride=1, padding=2)\n        )\n        \n        # 3x3 max pooling followed by 1x1 convolution branch\n        self.branch4 = nn.Sequential(\n            nn.MaxPool2d(kernel_size=3, stride=1, padding=1),\n            conv_block(in_channels, pool_proj, kernel_size=1, stride=1, padding=0)\n        )\n    \n    def forward(self, x):\n        branch1_output = self.branch1(x)\n        branch2_output = self.branch2(x)\n        branch3_output = self.branch3(x)\n        branch4_output = self.branch4(x)\n        output = torch.cat([branch1_output, branch2_output, branch3_output, branch4_output], 1)\n        return output\nclass GoogLeNet(nn.Module):\n    def __init__(self , in_channels , num_classes):\n        super(GoogLeNet ,self).__init__()\n        \n        self.conv1 = conv_block(in_channels , out_channels = 64 , kernel_size = (7,7)  ,stride = (2,2) ,padding  = (3,3))\n        self.conv1 = conv_block(in_channels=3, out_channels=64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        self.maxpool1 = nn.MaxPool2d(kernel_size = 3 , stride = 2 , padding =1)\n        self.conv2 = conv_block(64 , 192 , kernel_size = 3  ,stride = 1 ,padding  = 1)\n        self.maxpool2 = nn.MaxPool2d(kernel_size = 3 , stride = 2 , padding =1)\n\n        self.Inception3a = Inception_block(192 ,64 ,96 ,128 ,16 ,32 ,32)\n        self.Inception3b = Inception_block(256 ,128 ,128 ,192 ,32 ,96 ,64)\n        self.maxpool3 = nn.MaxPool2d(kernel_size = 3 , stride = 2 , padding =1)\n        \n        self.Inception4a = Inception_block(480 ,192 ,96 ,208 ,16 ,48 ,64)\n        self.Inception4b = Inception_block(512 ,160 ,112 ,224 ,24 ,64 ,64)\n        self.Inception4c = Inception_block(512 ,128 ,128 ,256 ,24 ,64 ,64)\n        self.Inception4d = Inception_block(512 ,112 ,114 ,288 ,32 ,64 ,64)\n        self.Inception4e = Inception_block(528 ,256 ,160 ,320 ,32 ,128 ,128)\n        \n        self.maxpool4 = nn.MaxPool2d(kernel_size = 3 ,stride = 2 , padding =1)\n        self.Inception5a = Inception_block(832 ,256 ,160 ,320 ,32 ,128 ,128)\n        self.Inception5b = Inception_block(832 ,384 ,192 ,384 ,48 ,128 ,128)\n        self.maxpool1 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n        self.maxpool2 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n        self.maxpool3 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n        self.maxpool4 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n\n        self.avgpool = nn.AvgPool2d(kernel_size = 7 , stride =  1)\n        self.avgpool = nn.AvgPool2d(kernel_size=1, stride=1)\n        self.dropout  = nn.Dropout2d(p=0.4)\n        self.fc1 = nn.Linear(4096 , num_classes)\n    \n    def forward(self ,x):\n        x = self.conv1(x)\n        x = self.maxpool1(x)\n        x = self.conv2(x)\n        x = self.maxpool2(x)\n        \n        x = self.Inception3a(x)\n        x = self.Inception3b(x)\n        x = self.maxpool3(x)\n        \n        x = self.Inception4a(x)\n        x = self.Inception4b(x)\n        x = self.Inception4c(x)\n        x = self.Inception4d(x)\n        x = self.Inception4e(x)\n        x = self.maxpool4(x)\n        \n        x = self.Inception5a(x)\n        x = self.Inception5b(x)\n        x = self.avgpool(x)\n        \n        x = x.reshape(x.shape[0], -1)\n        x = self.dropout(x)\n        x = self.fc1(x)\n        return x\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = GoogLeNet(in_channels=3 , num_classes=10)\nmodel.to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.SGD(model.parameters(), lr=0.001,momentum=0.9)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_epochs = 5\n# Training loop\ntrain_acc = []\ntrain_loss = []\nval_acc = []\nval_loss = []\nfor epoch in range(num_epochs):\n    running_loss = 0.0\n    correct_train = 0\n    total_train = 0\n\n    model.train()  # Set the model to training mode\n\n    for images, labels in train_loader:\n        images = images.to(device)  # Move the input tensor to the GPU\n        labels = labels.to(device)  # Move the labels tensor to the GPU\n\n        optimizer.zero_grad()\n        \n        # Forward pass\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n\n        # Backward pass and optimization\n        loss.backward()\n        optimizer.step()\n\n        running_loss += loss.item()\n\n        # Calculate training accuracy\n        _, predicted = torch.max(outputs.data, 1)\n        total_train += labels.size(0)\n        correct_train += (predicted == labels).sum().item()\n\n    training_loss = running_loss / len(train_loader)\n    training_accuracy = 100 * correct_train / total_train\n    \n\n    # Evaluation on test set\n    model.eval()  # Set the model to evaluation mode\n    test_loss = 0.0\n    correct_test = 0\n    total_test = 0\n\n    with torch.no_grad():\n        for images, labels in val_loader:\n            images = images.to(device)  # Move the input tensor to the GPU\n            labels = labels.to(device)  # Move the labels tensor to the GPU\n\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            test_loss += loss.item()\n\n            # Calculate test accuracy\n            _, predicted = torch.max(outputs.data, 1)\n            total_test += labels.size(0)\n            correct_test += (predicted == labels).sum().item()\n\n    test_loss /= len(val_loader)\n    test_accuracy = 100 * correct_test / total_test\n    \n    train_acc.append(training_accuracy)\n    train_loss.append(training_loss)\n    val_acc.append(test_accuracy)\n    val_loss.append(test_loss)\n\n    # Print the average loss and accuracy for this epoch\n    print(f\"Epoch {epoch+1}:\")\n    print(f\"  Train Loss: {training_loss:.4f} | Train Accuracy: {training_accuracy:.2f}%\")\n    print(f\"  Test Loss: {test_loss:.4f} | Test Accuracy: {test_accuracy:.2f}%\")\n    print(\"*************************\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_state = model.state_dict()\ntorch.save(final_state, 'model_state.pth')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\nt = f.suptitle('Basic CNN Performance', fontsize=12)\nf.subplots_adjust(top=0.85, wspace=0.3)\n\nepoch_list = list(range(1,num_epochs+1))\nax1.plot(epoch_list, train_acc, label='Train Accuracy')\nax1.plot(epoch_list, val_acc, label='Validation Accuracy')\nax1.set_xticks(np.arange(0, 60, 5))\nax1.set_ylabel('Accuracy Value')\nax1.set_xlabel('Epoch')\nax1.set_title('Accuracy')\nl1 = ax1.legend(loc=\"best\")\n\nax2.plot(epoch_list, train_loss, label='Train Loss')\nax2.plot(epoch_list, val_loss, label='Validation Loss')\nax2.set_xticks(np.arange(0, 60, 5))\nax2.set_ylabel('Loss Value')\nax2.set_xlabel('Epoch')\nax2.set_title('Loss')\nl2 = ax2.legend(loc=\"best\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}