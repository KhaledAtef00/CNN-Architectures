{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport tqdm\nimport torch\nimport torchvision\nimport torchvision.transforms as transforms\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nimport torch\nimport torchvision\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torchvision import datasets, transforms\nfrom torch.utils.data import DataLoader\nimport matplotlib.pyplot as plt","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if(torch.cuda.is_available()):\n    device = torch.device('cuda')\nelif(torch.backends.mps.is_available()):\n    device = torch.device('mps')\nelse:\n    device = torch.device('cpu')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"IMAGE_SIZE = 32\nbatch_size = 32\nmean, std = torch.tensor([0.4914, 0.4822, 0.4465]), torch.tensor([0.247, 0.243, 0.261])\n# These values are mostly used by researchers as found to very useful in fast convergence\n\n\ntransform = transforms.Compose([\n    transforms.RandomRotation(0.2) ,\n    transforms.RandomHorizontalFlip() ,\n    transforms.RandomVerticalFlip() ,\n    transforms.ColorJitter(),\n    transforms.ToTensor(),\n    transforms.Normalize(mean, std)\n])\n\n\n\ntrain_dataset = torchvision.datasets.CIFAR10(root='./data', train=True,download=True, transform=transform)\nval_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n\ntrain_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size , shuffle = True)\n\nval_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size , shuffle = False)\n\nclasses = [ 'airplane', 'automobile', 'bird', 'cat','deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n\n\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def imshow(img):\n    img = img / 2 + 0.5     # unnormalize\n    npimg = img.numpy()\n    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n    plt.show()\n\n\n# get some random training images\ndataiter = iter(train_loader)\nimages, labels = next(dataiter)\n\n# show images\nimshow(torchvision.utils.make_grid(images))\n# print labels\nprint(' '.join(f'{classes[labels[j]]:5s}' for j in range(batch_size)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(train_dataset.data.shape  , \" - \" , val_dataset.data.shape)\nprint(len(train_dataset.targets))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# functions to show an image\n\ndef unnormalize(img):\n        # unnormalize\n    img[0]= img[0]*std[0] + mean[0]\n    img[1]= img[1]*std[1] + mean[1]\n    img[2]= img[2]*std[2] + mean[2]\n    return img\n    \ndef imshow(img):\n    # unnormalize\n    img = unnormalize(img)\n    npimg = img.numpy()\n    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n    plt.show()\n    \ndef im_convert(tensor):\n    img = tensor.cpu().clone().detach().numpy() #\n    img = img.transpose(1, 2, 0)\n    img = img * np.array(tuple(mean)) + np.array(tuple(std))\n    img = img.clip(0, 1) # Clipping the size to print the images later\n    return img\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure(figsize=(20, 10)) \n\nfor i in range(len(classes)):\n    dataiter = iter(train_loader)\n    images, labels = next(dataiter)\n    for j in range (len(labels)):\n        if(labels[j].item() == i):\n            ax = fig.add_subplot(2, 5, i+1, xticks=[], yticks=[])\n            plt.imshow(im_convert(images[j]))\n            ax.set_title(classes[i])\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(len(classes)):\n    dataiter = iter(train_loader)\n    images, labels = next(dataiter)\n    for j in range (len(labels)):\n        if(labels[j].item() == i):\n            print(classes[i])\n            imshow(images[j])\n            break","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# class block(nn.Module):\n#     def __init__(\n#         self, in_channels, intermediate_channels, identity_downsample=None, stride=1\n#     ):\n#         super().__init__()\n#         self.expansion = 4\n#         self.conv1 = nn.Conv2d(\n#             in_channels,\n#             intermediate_channels,\n#             kernel_size=1,\n#             stride=1,\n#             padding=0,\n#             bias=False,\n#         )\n#         self.bn1 = nn.BatchNorm2d(intermediate_channels)\n#         self.conv2 = nn.Conv2d(\n#             intermediate_channels,\n#             intermediate_channels,\n#             kernel_size=3,\n#             stride=stride,\n#             padding=1,\n#             bias=False,\n#         )\n#         self.bn2 = nn.BatchNorm2d(intermediate_channels)\n#         self.conv3 = nn.Conv2d(\n#             intermediate_channels,\n#             intermediate_channels * self.expansion,\n#             kernel_size=1,\n#             stride=1,\n#             padding=0,\n#             bias=False,\n#         )\n#         self.bn3 = nn.BatchNorm2d(intermediate_channels * self.expansion)\n#         self.relu = nn.ReLU()\n#         self.identity_downsample = identity_downsample\n#         self.stride = stride\n\n#     def forward(self, x):\n#         identity = x.clone()\n\n#         x = self.conv1(x)\n#         x = self.bn1(x)\n#         x = self.relu(x)\n#         x = self.conv2(x)\n#         x = self.bn2(x)\n#         x = self.relu(x)\n#         x = self.conv3(x)\n#         x = self.bn3(x)\n\n#         if self.identity_downsample is not None:\n#             identity = self.identity_downsample(identity)\n\n#         x += identity\n#         x = self.relu(x)\n#         return x\n\n\n# class ResNet(nn.Module):\n#     def __init__(self, block, layers, image_channels, num_classes):\n#         super(ResNet, self).__init__()\n#         self.in_channels = 64\n#         self.conv1 = nn.Conv2d(\n#             image_channels, 64, kernel_size=7, stride=2, padding=3, bias=False\n#         )\n#         self.bn1 = nn.BatchNorm2d(64)\n#         self.relu = nn.ReLU()\n#         self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n\n#         # Essentially the entire ResNet architecture are in these 4 lines below\n#         self.layer1 = self._make_layer(\n#             block, layers[0], intermediate_channels=64, stride=1\n#         )\n#         self.layer2 = self._make_layer(\n#             block, layers[1], intermediate_channels=128, stride=2\n#         )\n#         self.layer3 = self._make_layer(\n#             block, layers[2], intermediate_channels=256, stride=2\n#         )\n#         self.layer4 = self._make_layer(\n#             block, layers[3], intermediate_channels=512, stride=2\n#         )\n\n#         self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n#         self.fc = nn.Linear(512 * 4, num_classes)\n\n#     def forward(self, x):\n#         x = self.conv1(x)\n#         x = self.bn1(x)\n#         x = self.relu(x)\n#         x = self.maxpool(x)\n#         x = self.layer1(x)\n#         x = self.layer2(x)\n#         x = self.layer3(x)\n#         x = self.layer4(x)\n\n#         x = self.avgpool(x)\n#         x = x.reshape(x.shape[0], -1)\n#         x = self.fc(x)\n\n#         return x\n\n#     def _make_layer(self, block, num_residual_blocks, intermediate_channels, stride):\n#         identity_downsample = None\n#         layers = []\n\n#         # Either if we half the input space for ex, 56x56 -> 28x28 (stride=2), or channels changes\n#         # we need to adapt the Identity (skip connection) so it will be able to be added\n#         # to the layer that's ahead\n#         if stride != 1 or self.in_channels != intermediate_channels * 4:\n#             identity_downsample = nn.Sequential(\n#                 nn.Conv2d(\n#                     self.in_channels,\n#                     intermediate_channels * 4,\n#                     kernel_size=1,\n#                     stride=stride,\n#                     bias=False,\n#                 ),\n#                 nn.BatchNorm2d(intermediate_channels * 4),\n#             )\n\n#         layers.append(\n#             block(self.in_channels, intermediate_channels, identity_downsample, stride)\n#         )\n\n#         # The expansion size is always 4 for ResNet 50,101,152\n#         self.in_channels = intermediate_channels * 4\n\n#         # For example for first resnet layer: 256 will be mapped to 64 as intermediate layer,\n#         # then finally back to 256. Hence no identity downsample is needed, since stride = 1,\n#         # and also same amount of channels.\n#         for i in range(num_residual_blocks - 1):\n#             layers.append(block(self.in_channels, intermediate_channels))\n\n#         return nn.Sequential(*layers)\n\n\n# def ResNet50(img_channel=3, num_classes=1000):\n#     return ResNet(block, [3, 4, 6, 3], img_channel, num_classes)\n\n\n# def ResNet101(img_channel=3, num_classes=1000):\n#     return ResNet(block, [3, 4, 23, 3], img_channel, num_classes)\n\n\n# def ResNet152(img_channel=3, num_classes=1000):\n#     return ResNet(block, [3, 8, 36, 3], img_channel, num_classes)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\n\nclass block(nn.Module):\n    def __init__(\n        self, in_channels, intermediate_channels, identity_downsample=None, stride=1\n    ):\n        super().__init__()\n        self.expansion = 4\n        self.conv1 = nn.Conv2d(\n            in_channels,\n            intermediate_channels,\n            kernel_size=1,\n            stride=1,\n            padding=0,\n            bias=False,\n        )\n        self.bn1 = nn.BatchNorm2d(intermediate_channels)\n        self.conv2 = nn.Conv2d(\n            intermediate_channels,\n            intermediate_channels,\n            kernel_size=3,\n            stride=stride,\n            padding=1,\n            bias=False,\n        )\n        self.bn2 = nn.BatchNorm2d(intermediate_channels)\n        self.conv3 = nn.Conv2d(\n            intermediate_channels,\n            intermediate_channels * self.expansion,\n            kernel_size=1,\n            stride=1,\n            padding=0,\n            bias=False,\n        )\n        self.bn3 = nn.BatchNorm2d(intermediate_channels * self.expansion)\n        self.relu = nn.ReLU()\n        self.identity_downsample = identity_downsample\n        self.stride = stride\n\n    def forward(self, x):\n        identity = x.clone()\n\n        x = self.conv1(x)\n        x = self.bn1(x)\n        x = self.relu(x)\n        x = self.conv2(x)\n        x = self.bn2(x)\n        x = self.relu(x)\n        x = self.conv3(x)\n        x = self.bn3(x)\n\n        if self.identity_downsample is not None:\n            identity = self.identity_downsample(identity)\n\n        x += identity\n        x = self.relu(x)\n        return x\n\n\nclass ResNet(nn.Module):\n    def __init__(self, block, layers, image_channels, num_classes):\n        super(ResNet, self).__init__()\n        self.in_channels = 64\n        self.conv1 = nn.Conv2d(\n            image_channels, 64, kernel_size=3, stride=1, padding=1, bias=False\n        )\n        self.bn1 = nn.BatchNorm2d(64)\n        self.relu = nn.ReLU()\n        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n\n        # Essentially the entire ResNet architecture are in these 4 lines below\n        self.layer1 = self._make_layer(\n            block, layers[0], intermediate_channels=64, stride=1\n        )\n        self.layer2 = self._make_layer(\n            block, layers[1], intermediate_channels=128, stride=2\n        )\n        self.layer3 = self._make_layer(\n            block, layers[2], intermediate_channels=256, stride=2\n        )\n        self.layer4 = self._make_layer(\n            block, layers[3], intermediate_channels=512, stride=2\n        )\n\n        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n        self.fc = nn.Linear(512, num_classes)\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.bn1(x)\n        x = self.relu(x)\n        x = self.maxpool(x)\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        x = self.layer4(x)\n\n        x = self.avgpool(x)\n        x = x.reshape(x.shape[0], -1)\n        x = self.fc(x)\n\n        return x\n\n    def _make_layer(self, block, num_residual_blocks, intermediate_channels, stride):\n        identity_downsample = None\n        layers = []\n\n        # Either if we half the input space for ex, 56x56 -> 28x28 (stride=2), or channels changes\n        # we need to adapt the Identity (skip connection) so it will be able to be added\n        # to the layer that's ahead\n        if stride != 1 or self.in_channels != intermediate_channels * 4:\n            identity_downsample = nn.Sequential(\n                nn.Conv2d(\n                    self.in_channels,\n                    intermediate_channels * 4,\n                    kernel_size=1,\n                    stride=stride,\n                    bias=False,\n                ),\n                nn.BatchNorm2d(intermediate_channels * 4),\n            )\n\n        layers.append(\n            block(self.in_channels, intermediate_channels, identity_downsample, stride)\n        )\n\n        # The expansion size is always 4 for ResNet 50,101,152\n        self.in_channels = intermediate_channels * 4\n\n        # For example for first resnet layer: 256 will be mapped to 64 as intermediate layer,\n        # then finally back to 256. Hence no identity downsample is needed, since stride = 1,\n        # and also same amount of channels.\n        for i in range(num_residual_blocks - 1):\n            layers.append(block(self.in_channels, intermediate_channels))\n\n        return nn.Sequential(*layers)\n\n\ndef ResNet50(img_channel=3, num_classes=1000):\n    return ResNet(block, [3, 4, 6, 3], img_channel, num_classes)\n\n\ndef ResNet101(img_channel=3, num_classes=1000):\n    return ResNet(block, [3, 4, 23, 3], img_channel, num_classes)\n\n\ndef ResNet152(img_channel=3, num_classes=1000):\n    return ResNet(block, [3, 8, 36, 3], img_channel, num_classes)\n\n# Assuming 'device' is defined, as in your code\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Instantiate the model\nmodel = ResNet101(3, 10)\nmodel.to(device)\n\n# Define loss and optimizer\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = ResNet101(3 , 10)\nmodel.to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.SGD(model.parameters(), lr=0.001,momentum=0.9)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_epochs = 5\n# Training loop\ntrain_acc = []\ntrain_loss = []\nval_acc = []\nval_loss = []\nfor epoch in range(num_epochs):\n    running_loss = 0.0\n    correct_train = 0\n    total_train = 0\n\n    model.train()  # Set the model to training mode\n\n    for images, labels in train_loader:\n        images = images.to(device)  # Move the input tensor to the GPU\n        labels = labels.to(device)  # Move the labels tensor to the GPU\n\n        optimizer.zero_grad()\n        \n        # Forward pass\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n\n        # Backward pass and optimization\n        loss.backward()\n        optimizer.step()\n\n        running_loss += loss.item()\n\n        # Calculate training accuracy\n        _, predicted = torch.max(outputs.data, 1)\n        total_train += labels.size(0)\n        correct_train += (predicted == labels).sum().item()\n\n    training_loss = running_loss / len(train_loader)\n    training_accuracy = 100 * correct_train / total_train\n    \n\n    # Evaluation on test set\n    model.eval()  # Set the model to evaluation mode\n    test_loss = 0.0\n    correct_test = 0\n    total_test = 0\n\n    with torch.no_grad():\n        for images, labels in val_loader:\n            images = images.to(device)  # Move the input tensor to the GPU\n            labels = labels.to(device)  # Move the labels tensor to the GPU\n\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            test_loss += loss.item()\n\n            # Calculate test accuracy\n            _, predicted = torch.max(outputs.data, 1)\n            total_test += labels.size(0)\n            correct_test += (predicted == labels).sum().item()\n\n    test_loss /= len(val_loader)\n    test_accuracy = 100 * correct_test / total_test\n    \n    train_acc.append(training_accuracy)\n    train_loss.append(training_loss)\n    val_acc.append(test_accuracy)\n    val_loss.append(test_loss)\n\n    # Print the average loss and accuracy for this epoch\n    print(f\"Epoch {epoch+1}:\")\n    print(f\"  Train Loss: {training_loss:.4f} | Train Accuracy: {training_accuracy:.2f}%\")\n    print(f\"  Test Loss: {test_loss:.4f} | Test Accuracy: {test_accuracy:.2f}%\")\n    print(\"*************************\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_state = model.state_dict()\ntorch.save(final_state, 'model_state.pth')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\nt = f.suptitle(' ResNet Performance', fontsize=12)\nf.subplots_adjust(top=0.85, wspace=0.3)\n\nepoch_list = list(range(1,num_epochs+1))\nax1.plot(epoch_list, train_acc, label='Train Accuracy')\nax1.plot(epoch_list, val_acc, label='Validation Accuracy')\nax1.set_xticks(np.arange(0, 60, 5))\nax1.set_ylabel('Accuracy Value')\nax1.set_xlabel('Epoch')\nax1.set_title('Accuracy')\nl1 = ax1.legend(loc=\"best\")\n\nax2.plot(epoch_list, train_loss, label='Train Loss')\nax2.plot(epoch_list, val_loss, label='Validation Loss')\nax2.set_xticks(np.arange(0, 60, 5))\nax2.set_ylabel('Loss Value')\nax2.set_xlabel('Epoch')\nax2.set_title('Loss')\nl2 = ax2.legend(loc=\"best\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}